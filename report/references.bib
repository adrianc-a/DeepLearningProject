
@article{AlphaGoZero,
	Author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	Date = {2017/10/18/online},
	Date-Added = {2017-11-19 08:17:56 +0000},
	Date-Modified = {2017-11-19 08:17:56 +0000},
	Day = {18},
	Journal = {Nature},
	L3 = {10.1038/nature24270; https://www.nature.com/articles/nature24270#supplementary-information}, M3 = {Article}, Month = {10},
	Pages = {354 EP  -},
	Publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved. SN  -},
	Title = {Mastering the game of Go without human knowledge},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature24270},
	Volume = {550},
	Year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature24270}
}


@article{AlphaGo,
	Author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	Date = {2016/01/27/online},
	Date-Added = {2017-12-04 08:57:07 +0000},
	Date-Modified = {2017-12-04 08:57:07 +0000},
	Day = {27},
	Journal = {Nature},
	L3 = {10.1038/nature16961; https://www.nature.com/articles/nature16961#supplementary-information},
	M3 = {Article},
	Month = {01},
	Pages = {484 EP  -},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
	Title = {Mastering the game of Go with deep neural networks and tree search},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature16961},
	Volume = {529},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature16961}}

@article{eight,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  archivePrefix = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Wed, 07 Jun 2017 14:43:09 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/MnihBMGLHSK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{nine,
  author    = {Max Jaderberg and
               Volodymyr Mnih and
               Wojciech Marian Czarnecki and
               Tom Schaul and
               Joel Z. Leibo and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Reinforcement Learning with Unsupervised Auxiliary Tasks},
  journal   = {CoRR},
  volume    = {abs/1611.05397},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05397},
  archivePrefix = {arXiv},
  eprint    = {1611.05397},
  timestamp = {Wed, 07 Jun 2017 14:40:03 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/JaderbergMCSLSK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{one,
author="Baxter, Jonathan
and Tridgell, Andrew
and Weaver, Lex",
title="Learning to Play Chess Using Temporal Differences",
journal="Machine Learning",
year="2000",
month="Sep",
day="01",
volume="40",
number="3",
pages="243--263",
abstract="In this paper we present TDLEAF($\lambda$), a variation on the TD($\lambda$) algorithm that enables it to be used in conjunction with game-tree search. We present some experiments in which our chess program ``KnightCap'' used TDLEAF($\lambda$) to learn its evaluation function while playing on Internet chess servers. The main success we report is that KnightCap improved from a 1650 rating to a 2150 rating in just 308 games and 3 days of play. As a reference, a rating of 1650 corresponds to about level B human play (on a scale from E (1000) to A (1800)), while 2150 is human master level. We discuss some of the reasons for this success, principle among them being the use of on-line, rather than self-play. We also investigate whether TDLEAF($\lambda$) can yield better results in the domain of backgammon, where TD($\lambda$) has previously yielded striking success.",
issn="1573-0565",
doi="10.1023/A:1007634325138",
url="https://doi.org/10.1023/A:1007634325138"
}

@article{ten,
  author    = {Alexey Dosovitskiy and
               Vladlen Koltun},
  title     = {Learning to Act by Predicting the Future},
  journal   = {CoRR},
  volume    = {abs/1611.01779},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01779},
  archivePrefix = {arXiv},
  eprint    = {1611.01779},
  timestamp = {Wed, 07 Jun 2017 14:43:00 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/DosovitskiyK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{three,
  author    = {Matthew Lai},
  title     = {Giraffe: Using Deep Reinforcement Learning to Play Chess},
  journal   = {CoRR},
  volume    = {abs/1509.01549},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.01549},
  archivePrefix = {arXiv},
  eprint    = {1509.01549},
  timestamp = {Wed, 07 Jun 2017 14:41:14 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/Lai15a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{two,
title = {Bootstrapping from Game Tree Search},
author = {Veness, Joel and Silver, David and Alan Blair and Uther, William},
booktitle = {Advances in Neural Information Processing Systems 22},
editor = {Y. Bengio and D. Schuurmans and J. D. Lafferty and C. K. I. Williams and A. Culotta},
pages = {1937--1945},
year = {2009},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/3722-bootstrapping-from-game-tree-search.pdf}
}

@article{Elo,
    Author = {Glickman, Mark and Doan, Thomas},
    Date = {2017/04/24},
    Title = {The U.S Chess Rating System},
    Url = {http://www.glicko.net/ratings/rating.system.pdf}
}

@article{Residual,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{tensorflow,
title = {TensorFlow: A system for large-scale machine learning},
author  = {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year  = {2016},
URL = {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages = {265--283}
}


@Article{puct,
author="Rosin, Christopher D.",
title="Multi-armed bandits with episode context",
journal="Annals of Mathematics and Artificial Intelligence",
year="2011",
month="Mar",
day="01",
volume="61",
number="3",
pages="203--230",
abstract="A multi-armed bandit episode consists of n trials, each allowing selection of one of K arms,
resulting in payoff from a distribution over [0,1] associated with that arm. We assume contextual side
information is available at the start of the episode. This context enables an arm predictor to identify
 possible favorable arms, but predictions may be imperfect so that they need to be combined with furthe
r exploration during the episode. Our setting is an alternative to classical multi-armed bandits which
provide no contextual side information, and is also an alternative to contextual bandits which provide
new context each individual trial. Multi-armed bandits with episode context can arise naturally, for ex
ample in computer Go where context is used to bias move decisions made by a multi-armed bandit algorith
m. The UCB1 algorithm for multi-armed bandits achieves worst-case regret bounded by
                                                       {\$}O{\backslash}left({\backslash}sqrt{\{}Kn{\ba
ckslash}log(n){\}}{\backslash}right){\$}                . We seek to improve this using episode context
, particularly in the case where K is large. Using a predictor that places weight M
              i                {\thinspace}>{\thinspace}0 on arm i with weights summing to 1, we presen
t the PUCB algorithm which achieves regret
              {\$}O{\backslash}left({\backslash}frac{\{}1{\}}{\{}M{\_}{\{}{\backslash}ast{\}}{\}}{\back
slash}sqrt{\{}n{\backslash}log(n){\}}{\backslash}right){\$}                 where M                {\th
inspace}âˆ—{\thinspace} is the weight on the optimal arm. We illustrate the behavior of PUCB with small s
imulation experiments, present extensions that provide additional capabilities for PUCB, and describe m
ethods for obtaining suitable predictors for use with PUCB.",
issn="1573-7470",
doi="10.1007/s10472-011-9258-6",
url="https://doi.org/10.1007/s10472-011-9258-6"
}



@article{dqn,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Date = {2015/02/25/online},
	Date-Added = {2017-12-05 01:45:47 +0000},
	Date-Modified = {2017-12-05 01:45:47 +0000},
	Day = {25},
	Journal = {Nature},
	L3 = {10.1038/nature14236; https://www.nature.com/articles/nature14236#supplementary-information},
	Month = {02},
	Pages = {529 EP  -},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
	Title = {Human-level control through deep reinforcement learning},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature14236},
	Volume = {518},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature14236}}


@misc{deepmind,
  title = {AlphaGo Home},
  howpublished = {\url{https://deepmind.com/research/alphago/}},
  note = {Accessed: 2017-12-04}
}
